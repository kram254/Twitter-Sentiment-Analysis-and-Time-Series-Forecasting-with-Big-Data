{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c90a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from fbprophet import Prophet\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2e4ca1",
   "metadata": {},
   "source": [
    "### Initialize a Spark session that connects to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc8cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"SentimentTimeSeries\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://127.0.0.1:27017/mydb.mycollection\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://127.0.0.1:27017/mydb.mycollection\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acef82f",
   "metadata": {},
   "source": [
    "### Reading data from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b923d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = spark.read.format(\"mongo\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a75b396",
   "metadata": {},
   "source": [
    "### Sentiment analysis preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f75dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0aa8af",
   "metadata": {},
   "source": [
    "### Assemble pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cdfb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc9228",
   "metadata": {},
   "source": [
    "### Train the sentiment analysis model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d5136",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deab6657",
   "metadata": {},
   "source": [
    "### Assume the sentiment data is already in 'df' with 'timestamp' and 'sentiment' columns\n",
    "#### Select relevant columns and convert to pandas for Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44aaaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = df.select(\"timestamp\", \"sentiment\").withColumnRenamed(\"timestamp\", \"ds\").withColumnRenamed(\"sentiment\", \"y\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d9aa81",
   "metadata": {},
   "source": [
    "### Initialize and fit the Prophet model for time series forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d5ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_model = Prophet()\n",
    "prophet_model.fit(pandas_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77456b7b",
   "metadata": {},
   "source": [
    "### Create future dataframe for forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "future_week = prophet_model.make_future_dataframe(periods=7)\n",
    "future_month = prophet_model.make_future_dataframe(periods=30)\n",
    "future_3month = prophet_model.make_future_dataframe(periods=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f58403c",
   "metadata": {},
   "source": [
    "#### Perform forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f63dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forecast_week = prophet_model.predict(future_week)\n",
    "forecast_month = prophet_model.predict(future_month)\n",
    "forecast_3month = prophet_model.predict(future_3month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde91fc5",
   "metadata": {},
   "source": [
    "### The forecasts can now be used or saved back to MongoDB\n",
    "### This is just an example of converting a forecast back to a Spark DataFrame and saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a0667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_week_df = spark.createDataFrame(forecast_week)\n",
    "forecast_week_df.write.format(\"mongo\").mode(\"overwrite\").option(\"collection\", \"forecast_week_collection\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0400f89a",
   "metadata": {},
   "source": [
    "### Close the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf25cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
